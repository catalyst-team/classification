model_params:
  fp16: false
  model: MultiHeadNet
  encoder_params:
    arch: resnet18
    pretrained: True
    frozen: True
    pooling: GlobalConcatPool2d
  embedding_net_params:
    hiddens: [256]
    activation_fn: ReLU
    norm_fn: BatchNorm1d
    bias: false
    dropout: 0.5
  heads_params:
    logits: &num_classes 2

args:
  expdir: "src"
  logdir: &logdir "./logs/lrfiner"
  baselogdir: "./logs/lrfiner"

stages:

  state_params:
    main_metric: &reduce_metric loss
    minimize_metric: True
    valid_loader: train

  criterion_params:
    criterion: CrossEntropyLoss

  # train head
  stage1:

    state_params:
      num_epochs: 100

    data_params: &data_params
      num_workers: 6
      batch_size: 64
      per_gpu_batch_size: True
      in_csv_train: "./data/dataset_train.csv"
      datapath: "./data/dataset"

    optimizer_params:
      optimizer: Adam
      lr: 0.001
      weight_decay: 0.0001

    scheduler_params:
      scheduler: MultiStepLR
      milestones: [8]
      gamma: 0.3

    callbacks_params:
      loss:
        callback: EmbeddingsLossCallback
        emb_l2_reg: -1
        input_key: targets
        embeddings_key: embeddings
        output_key: logits
      optimizer:
        callback: OptimizerCallback
      finder:
        callback: LRFinder
        final_lr: 0.01
        num_steps: 1000
