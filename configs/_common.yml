model_params:
  model: MultiHeadNet
  encoder_params:
    arch: resnet18
    pretrained: True
    frozen: True
    pooling: MaxPool2d
    pooling_kwargs:
      kernel_size: 7      # [14, 7]
      stride: 7           # [14, 7]
  embedding_net_params:
    hiddens: [512]
    layer_fn: {"module": "Linear", "bias": False}
    norm_fn: BatchNorm1d
    activation_fn: ReLU
    dropout_fn: Dropout
    residual: "soft"

stages:

  # train head
  stage1:
    state_params:
      num_epochs: 8

    optimizer_params:
#      optimizer: Lookahead
#      base_optimizer_params:
      optimizer: Adam
      lr: 0.001
      weight_decay: 0.0001

    scheduler_params:
      scheduler: MultiStepLR
      milestones: [8]
      gamma: 0.3

  # tune whole network
  stage2:
    state_params:
      num_epochs: 24

    optimizer_params:
#      optimizer: Lookahead
#      base_optimizer_params:
      optimizer: Adam
      lr: 0.0003

    scheduler_params:
      scheduler: MultiStepLR
      milestones: [12, 20]
      gamma: 0.3
